{"cells":[{"cell_type":"markdown","source":["### Environment Preparation"],"metadata":{"id":"Xn3iO686L0Jj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3L4-aZo03uQz"},"outputs":[],"source":["# code to set the python version to 3.8\n","# !sudo update-alternatives --config python3\n","# !python -V\n","# !sudo apt-get install python3-pip\n","# !python -m pip install --upgrade pip\n","# !pip install ipykernel"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQjp6qejYfuW","executionInfo":{"status":"ok","timestamp":1683114435879,"user_tz":-600,"elapsed":8795,"user":{"displayName":"Yixin Shen","userId":"08723041619229600532"}},"outputId":"089f1c7d-f049-4963-a3bd-0f666d57e88f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.1+cu118)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n","Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.31)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.21.1)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.2)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"]}],"source":["!pip install torch torchvision transformers\n","!pip install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KHo9cD6v4zJX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683114438633,"user_tz":-600,"elapsed":2760,"user":{"displayName":"Yixin Shen","userId":"08723041619229600532"}},"outputId":"155dee28-e088-4d3a-f463-a7f7b0a3e99a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","import json\n","import random\n","from tqdm import tqdm\n","import torch.nn.functional as F\n","import torch\n","import numpy as np\n","from datetime import datetime\n","from transformers import AutoTokenizer, AutoModel\n","import wandb\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","import os\n","import pickle"],"metadata":{"id":"prJUeEfRKfCH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Evidence Retrieval Dataset"],"metadata":{"id":"wbMz3cp1L3mQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BRtUbg9XqC_6"},"outputs":[],"source":["# function to merge two dictionaries\n","def Merge(dict1, dict2):\n","    res = {**dict1, **dict2}\n","    return res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m2xLzntt5g6z"},"outputs":[],"source":["# Process the training dataset\n","class TrainDataset(Dataset):\n","  def __init__(self, mode, tokenizer, evidence_samples, max_length):\n","    self.mode = mode\n","    self.tokenizer = tokenizer\n","    self.evidence_samples = evidence_samples\n","    self.max_length = max_length\n","    \n","    # use both the train and dev datasets to train the model\n","    if mode == \"train_dev\":\n","      f = open(\"./drive/MyDrive/NLP_ass3/data/train-claims.json\", \"r\")\n","      train_dataset = json.load(f)\n","      f.close()\n","\n","      f = open(\"./drive/MyDrive/NLP_ass3/data/dev-claims.json\", \"r\")\n","      dev_dataset = json.load(f)\n","      f.close()\n","\n","      self.dataset = Merge(train_dataset, dev_dataset)\n","    else:\n","      # open the train/dev file\n","      f = open(\"./drive/MyDrive/NLP_ass3/data/{}-claims.json\".format(mode), \"r\")\n","      self.dataset = json.load(f)\n","      f.close()\n","    self.claim_ids = list(self.dataset.keys())\n","    \n","    # open the evidence file \n","    f = open(\"./drive/MyDrive/NLP_ass3/data/evidence.json\", \"r\")\n","    self.evidences = json.load(f)\n","    f.close()\n","    self.evidence_ids = list(self.evidences.keys())\n","\n","  def __len__(self):\n","    return len(self.claim_ids)\n","\n","  def __getitem__(self, index):\n","    claim_id = self.claim_ids[index]\n","    data = self.dataset[claim_id]\n","    processed_query = data[\"claim_text\"].lower()\n","    evidences = []\n","    for evidence_id in data[\"evidences\"]:\n","      evidences.append(evidence_id)\n","    return [processed_query, evidences]\n","\n","  def collate_fn(self, batch):\n","    queries = []\n","    evidences = []\n","    answer_lens = []\n","    for query, evidence in batch:\n","      queries.append(query)\n","      evidences.extend(evidence)\n","      answer_lens.append(len(evidence))\n","    \n","    # set some negative example for training\n","    evidence_num = len(evidences)\n","    # if the number of evidence is larger than example setting, trancate the evidence list\n","    if evidence_num > self.evidence_samples:\n","      evidences = evidences[:self.evidence_samples]\n","\n","    # if the number of evidence is less than example setting,\n","    # randomly choose evidence from the dataset while proving there is no duplication\n","    evidences_text = [self.evidences[evidence_id].lower() for evidence_id in evidences]\n","    while evidence_num < self.evidence_samples:\n","      evidence_id = random.choice(self.evidence_ids)\n","      while evidence_id in evidences:\n","        evidence_id = random.choice(self.evidence_ids)\n","      evidences.append(evidence_id)\n","      evidences_text.append(self.evidences[evidence_id].lower())\n","      evidence_num += 1\n","\n","    query_text_token = self.tokenizer(\n","        queries,\n","        max_length=self.max_length,\n","        padding=True,\n","        truncation=True,\n","        return_tensors=\"pt\"\n","    )\n","\n","    evidences_text_token = self.tokenizer(\n","        evidences_text,\n","        max_length=self.max_length,\n","        padding=True,\n","        truncation=True,\n","        return_tensors=\"pt\"\n","    )\n","\n","    encoding_dict = {\"query_input_ids\" : query_text_token[\"input_ids\"],\n","            \"evidence_input_ids\" : evidences_text_token[\"input_ids\"],\n","            \"query_attention_mask\" : query_text_token[\"attention_mask\"],\n","            \"evidence_attention_mask\" : evidences_text_token[\"attention_mask\"],\n","            \"answer_lens\" : answer_lens}\n","    return encoding_dict\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AQykm8PdovGY"},"outputs":[],"source":["# Process the validate dataset\n","class ValidateDataset(Dataset):\n","  def __init__(self, mode, tokenizer, max_length):\n","    self.tokenizer = tokenizer\n","    self.mode = mode\n","    self.max_length = max_length\n","\n","    # open the dev/test file\n","    if mode != \"test\":\n","      f = open(\"./drive/MyDrive/NLP_ass3/data/{}-claims.json\".format(mode), \"r\")\n","    else:\n","      f = open(\"./drive/MyDrive/NLP_ass3/data/test-claims-unlabelled.json\", \"r\")\n","\n","    self.dataset = json.load(f)\n","    f.close()\n","\n","    # read the claim ids to a list\n","    self.claim_ids = list(self.dataset.keys())\n","\n","  def __len__(self):\n","    return len(self.claim_ids)\n","  \n","  def __getitem__(self, index):\n","    claim_id = self.claim_ids[index]\n","    data = self.dataset[claim_id]\n","    processed_query = data[\"claim_text\"].lower()\n","    return [processed_query, data, claim_id]\n","\n","  def collate_fn(self, batch):\n","    queries = []\n","    datas = []\n","    claim_ids = []\n","    evidences = []\n","    # print(\"read the dev file 1111\")\n","\n","    for query, data, claim_id in batch:\n","      queries.append(query)\n","      datas.append(data)\n","      claim_ids.append(claim_id)\n","      if self.mode != \"test\":\n","        evidences.append(data[\"evidences\"])\n","\n","    # print(\"read the dev file\")\n","\n","    query_text_token = self.tokenizer(\n","      queries,\n","      max_length=self.max_length,\n","      padding=True,\n","      truncation=True,\n","      return_tensors=\"pt\"\n","    )\n","\n","    encoding_dict = {\"query_input_ids\" : query_text_token[\"input_ids\"],\n","              \"query_attention_mask\" : query_text_token[\"attention_mask\"],\n","              \"datas\" : datas,\n","              \"claim_ids\" : claim_ids}\n","    # if the file is dev, encode the evidences into the encodings\n","    if self.mode != \"test\":\n","      encoding_dict[\"evidences\"] = evidences\n","    return encoding_dict\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z7yVpCrjoyow"},"outputs":[],"source":["# Process the evidence dataset\n","class EvidenceDataset(Dataset):\n","  def __init__(self, tokenizer, max_length):\n","    self.tokenizer = tokenizer\n","    self.max_length = max_length\n","\n","    f = open(\"./drive/MyDrive/NLP_ass3/data/evidence.json\", \"r\")\n","    self.evidences = json.load(f)\n","    f.close()\n","\n","    self.evidences_ids = list(self.evidences.keys())\n","\n","  def __len__(self):\n","    return len(self.evidences_ids)\n","\n","  def __getitem__(self, index):\n","    evidences_id = self.evidences_ids[index]\n","    evidence = self.evidences[evidences_id]\n","    return [evidences_id, evidence]\n","    \n","  def collate_fn(self, batch):\n","    evidences_ids = []\n","    evidences = []\n","\n","    for evidences_id, evidence in batch:\n","      evidences_ids.append(evidences_id)\n","      evidences.append(evidence.lower())\n","\n","    evidences_text_token = self.tokenizer(\n","        evidences,\n","        max_length=self.max_length,\n","        padding=True,\n","        truncation=True,\n","        return_tensors=\"pt\"\n","    )\n","\n","    encoding_dict = {\"evidence_input_ids\" : evidences_text_token[\"input_ids\"],\n","               \"evidence_attention_mask\" : evidences_text_token[\"attention_mask\"],\n","               \"evidences_ids\" : evidences_ids}\n","\n","    return encoding_dict"]},{"cell_type":"markdown","source":["### Auxiliary Functions"],"metadata":{"id":"pNbtqaFHL_h5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-6eSLtEnZ_K3"},"outputs":[],"source":["# function to set the random seed\n","def setup_seed(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rBzWC5B0yZWU"},"outputs":[],"source":["def set_cuda(batch):\n","  for key in batch.keys():\n","    if key in [\"query_input_ids\", \"evidence_input_ids\", \"query_attention_mask\", \"evidence_attention_mask\"]:\n","      batch[key] = batch[key].cuda()"]},{"cell_type":"markdown","source":["### Generate and save the evidences embedings and ids"],"metadata":{"id":"7cL0EmNBLlCg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"LJqIVpOAgQNL"},"outputs":[],"source":["# the function to get the evidence embeddings\n","def Generate_E_Embedding():\n","  # define the model_name\n","  model_name = \"bert-base-uncased\"\n","\n","  # get the tokenizer from the specific model\n","  tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","  # initialize the pretrained model\n","  model = AutoModel.from_pretrained(model_name)\n","\n","  model.cuda()\n","  model.eval()\n","\n","  evidence_dataset = EvidenceDataset(tokenizer, max_length=128)\n","  evidence_DataLoader = DataLoader(evidence_dataset, batch_size=128, shuffle=False, num_workers=8, collate_fn=evidence_dataset.collate_fn)\n","\n","  e_embeddings = []\n","  e_ids = []\n","  for batch in tqdm(evidence_DataLoader):\n","    set_cuda(batch)\n","    # get the last hidden layer, detach the embedding from the logits\n","    e_outputs = model(input_ids=batch[\"evidence_input_ids\"], attention_mask=batch[\"evidence_attention_mask\"])\n","    e_logits = e_outputs.last_hidden_state\n","    e_embedding = e_logits[:, 0, :].detach()\n","\n","    # transfer the e_embedding to cpu\n","    e_embedding_cpu = F.normalize(e_embedding).cpu()\n","    del e_logits, e_embedding\n","\n","    # append the data to list\n","    e_embeddings.append(e_embedding_cpu)\n","    e_ids.extend(batch[\"evidences_ids\"])\n","\n","  e_embeddings = torch.cat(e_embeddings, dim=0).t()\n","  \n","  torch.save(e_embeddings, \"./drive/MyDrive/NLP_ass3/embedding_ids/e_embedding.pth\")\n","\n","  file = open(\"./drive/MyDrive/NLP_ass3/embedding_ids/e_ids.pkl\", 'wb')\n","  r = pickle.dump(e_ids, file)\n","  file.close()\n","\n","  print(e_embedding)\n","  print(e_ids)"]},{"cell_type":"code","source":["# Generate_E_Embedding()"],"metadata":{"id":"nLRH-WhDORFr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# the function to get the evidence embeddings\n","def embed_evidence(evidence_DataLoader, model):\n","  # set the model to evaluate mode\n","  model.eval()\n","  e_embeddings = []\n","  e_ids = []\n","  for batch in tqdm(evidence_DataLoader):\n","    set_cuda(batch)\n","    # get the last hidden layer, detach the embedding from the logits\n","    e_outputs = model(input_ids=batch[\"evidence_input_ids\"], attention_mask=batch[\"evidence_attention_mask\"])\n","    e_logits = e_outputs.last_hidden_state\n","    e_embedding = e_logits[:, 0, :].detach()\n","\n","    # transfer the e_embedding to cpu\n","    e_embedding_cpu = F.normalize(e_embedding).cpu()\n","    del e_logits, e_embedding\n","\n","    # append the data to list\n","    e_embeddings.append(e_embedding_cpu)\n","    e_ids.extend(batch[\"evidences_ids\"])\n","\n","  e_embeddings = torch.cat(e_embeddings, dim=0).t()\n","  return e_embeddings, e_ids"],"metadata":{"id":"JnkkrugwVG3O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Crucial Functions"],"metadata":{"id":"NOs7Clt5MIV9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"oCxfvQRMw8IN"},"outputs":[],"source":["def evaluate(val_DataLoader, evidence_embeddings, evidence_ids, model, top_evidence):\n","  # set the model to evaluate mode\n","  model.eval()\n","  \n","  f_scores = []\n","  for batch in tqdm(val_DataLoader):\n","    set_cuda(batch)\n","    # get the last hidden layer, detach the embedding from the logits\n","    q_outputs = model(input_ids=batch[\"query_input_ids\"], attention_mask=batch[\"query_attention_mask\"])\n","    q_logits = q_outputs.last_hidden_state\n","    q_embedding = q_logits[:, 0, :]\n","\n","    # transfer the q_embedding to cpu\n","    q_embedding_cpu = F.normalize(q_embedding).cpu()\n","    \n","    # get the evidences scores seperately and select the top ones\n","    similarity_scores = torch.mm(q_embedding_cpu, evidence_embeddings)\n","    batch_e_ids = torch.topk(similarity_scores, k=top_evidence, dim=1).indices.tolist()\n","\n","    for index, data in enumerate(batch[\"datas\"]):\n","        top_k_ids = batch_e_ids[index]\n","        top_e_ids = [evidence_ids[id] for id in top_k_ids]\n","        correct_evidence = [e_id for e_id in batch[\"evidences\"][index] if e_id in top_e_ids]\n","        \n","        if len(correct_evidence) > 0:\n","            recall = len(correct_evidence) / len(batch[\"evidences\"][index])\n","            precision = len(correct_evidence) / len(top_e_ids)\n","            f_score = (2 * precision * recall) / (precision + recall)\n","        else:\n","            f_score = 0\n","        f_scores.append(f_score)\n","\n","  f_socre_final = np.mean(f_scores)\n","  print(\"\\nEvidence Retrieval F-score = %.3f\\n\" % f_socre_final)\n","\n","  # set the model back to train mode\n","  model.train()\n","\n","  return f_socre_final"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R1Hdk358P0dr"},"outputs":[],"source":["def train(model_name, epoch, batch_size, max_length, evidence_samples, top_evidence, model_path):\n","  # initiate the wandb\n","  wandb.init(project=\"Task1 Evidence Retrieval\", name=\"BERT\")\n","\n","  # set the random seed of the model\n","  setup_seed(42)\n","\n","  # create the folder to save the model trained  \n","  month_date = datetime.now().strftime(\"%m-%d\")\n","  checkpoints_dir_path = f\"./drive/MyDrive/NLP_ass3/checkpoints/{month_date}\"\n","  if not os.path.exists(checkpoints_dir_path):\n","    os.makedirs(checkpoints_dir_path)\n","  \n","  # initialize the pretrained model\n","  model = AutoModel.from_pretrained(model_name)\n","  if model_path != \"\":\n","      model.load_state_dict(torch.load(os.path.join(\"./drive/MyDrive/NLP_ass3/checkpoints\", model_path, \"best_state_dict.bin\")))\n","\n","  # use GPU to train the model\n","  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","  # print(device)\n","  model.to(device)\n","  # set model to train mode\n","  model.train()\n","\n","  # get the tokenizer from the specific model\n","  tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","  # initialize the datasets and read to the DataLoader for feeding into the model\n","  train_dataset = TrainDataset(\"train\", tokenizer, evidence_samples, max_length)\n","  val_dataset = ValidateDataset(\"dev\", tokenizer, max_length)\n","  evidence_dataset = EvidenceDataset(tokenizer, max_length)\n","\n","  train_DataLoader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, collate_fn=train_dataset.collate_fn)\n","  val_DataLoader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=8, collate_fn=val_dataset.collate_fn)\n","  evidence_DataLoader = DataLoader(evidence_dataset, batch_size=128, shuffle=False, num_workers=8, collate_fn=evidence_dataset.collate_fn)\n","\n","  # TODO: here to change the optimizer\n","  # TODO: adjust the lr\n","  optimizer = optim.Adam(model.parameters(), lr=2e-5)\n","\n","  # set some counter for training\n","  update_count = 0\n","  avg_loss = 0\n","  max_f_score = 0\n","  epoch_num = 0\n","\n","  # get the evidence embedding for scoring\n","  # evidence_embeddings, evidence_ids = embed_evidence(evidence_DataLoader, model)\n","\n","  evidence_embeddings = torch.load(\"./drive/MyDrive/NLP_ass3/embedding_ids/e_embedding.pth\")\n","\n","  evidence_ids=[]\n","  file=open(r\"./drive/MyDrive/NLP_ass3/embedding_ids/e_ids.pkl\",\"rb\")\n","  evidence_ids=pickle.load(file)\n","\n","  f_score = evaluate(val_DataLoader, evidence_embeddings, evidence_ids, model, top_evidence)\n","  wandb.log({\"f_score\": f_score}, step=epoch_num)\n","\n","  # assign the f_score to max_f_score\n","  max_f_score = f_score\n","  \n","  for epoch in range(epoch):\n","    print(\"##################################################Training##################################################\")\n","    # use to save the count of epoch update step\n","    for (idx, batch) in enumerate(tqdm(train_DataLoader)):\n","      # start training\n","      optimizer.zero_grad()\n","      \n","      # put the data in batch into cuda\n","      set_cuda(batch)\n","\n","      # get the embeddings of the q and e according \n","      q_outputs = model(input_ids=batch[\"query_input_ids\"], attention_mask=batch[\"query_attention_mask\"])\n","      q_logits = q_outputs.last_hidden_state\n","\n","      e_outputs = model(input_ids=batch[\"evidence_input_ids\"], attention_mask=batch[\"evidence_attention_mask\"])\n","      e_logits = e_outputs.last_hidden_state\n","      \n","      q_embeddings = q_logits[:, 0, :]\n","      e_embeddings = e_logits[:, 0, :]\n","\n","      # normalize the embeddings\n","      q_embeddings = F.normalize(q_embeddings)\n","      e_embeddings = F.normalize(e_embeddings)\n","\n","      # calculate the cosine similarity between the queries and evidences\n","      cos_similarities = torch.mm(q_embeddings, e_embeddings.t())\n","      # prevent overflow, accelarate back propogation\n","      log_soft_scores = - F.log_softmax(cos_similarities, dim=1)\n","\n","      loss_list = []\n","      start_index = 0\n","      for index, answer_len in enumerate(batch[\"answer_lens\"]):\n","        end_index = start_index + answer_len\n","        current_loss = torch.mean(log_soft_scores[index, start_index:end_index])\n","        loss_list.append(current_loss)\n","        start_index = end_index\n","\n","      loss = torch.stack(loss_list).mean()\n","      \n","      # backward the loss, update the parameters in the model\n","      loss.backward()\n","      avg_loss = avg_loss + loss.item()\n","\n","      # optimize the model\n","      optimizer.step()\n","\n","      update_count += 1\n","\n","      wandb_freq = 20\n","      if update_count % wandb_freq == 0:\n","        wandb.log({\"loss\": avg_loss / wandb_freq}, step=update_count)\n","        avg_loss = 0\n","\n","    print(\"##################################################Evaluate##################################################\")\n","    # finish one epoch, add one to the epoch_num\n","    epoch_num += 1\n","    # evaluate the model every epoch and save the best one that have the best f_score\n","    # evidence_embeddings, evidence_ids = embed_evidence(evidence_DataLoader, model)\n","    f_score = evaluate(val_DataLoader, evidence_embeddings, evidence_ids, model, top_evidence)\n","    wandb.log({\"f_score\": f_score}, step=update_count)\n","\n","    if f_score > max_f_score:\n","      max_f_score = f_score\n","      torch.save(model.state_dict(), os.path.join(checkpoints_dir_path, \"best_state_dict.bin\"))\n","      print(\"\\nThis is the\", epoch_num, \"epoch\", \"the max f_score is\", max_f_score)\n","  # finish the wandb\n","  wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SchJbuxhRgoH"},"outputs":[],"source":["def predict(model_name, batch_size, max_length, top_evidence, model_path):\n","  # get the tokenizer from the specific model\n","  tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","  # initialize the pretrained model\n","  model = AutoModel.from_pretrained(model_name)\n","\n","  # load the best finetuned parameters\n","  assert model_path\n","  # print(os.path.join(\"./drive/MyDrive/NLP_ass3/checkpoints\", model_path, \"best_state_dict.bin\"))\n","  model.load_state_dict(torch.load(os.path.join(\"./drive/MyDrive/NLP_ass3/checkpoints\", model_path, \"best_state_dict.bin\")))\n","\n","  # use GPU, and set the model to evaluate mode\n","  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","  # print(device)\n","  model.to(device)\n","\n","  # load the test and evidence datasets\n","  test_dataset = ValidateDataset(\"test\", tokenizer, max_length)\n","  evidence_dataset = EvidenceDataset(tokenizer, max_length)\n","\n","  test_DataLoader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8, collate_fn=test_dataset.collate_fn)\n","  evidence_DataLoader = DataLoader(evidence_dataset, batch_size=128, shuffle=False, num_workers=8, collate_fn=evidence_dataset.collate_fn)\n","\n","\n","  # utilize embed_evidence function to get the evidences embeddings\n","  # evidence_embeddings, evidence_ids = embed_evidence(evidence_DataLoader, model)\n","  evidence_embeddings = torch.load(\"./drive/MyDrive/NLP_ass3/embedding_ids/e_embedding.pth\")\n","  \n","  evidence_ids=[]\n","  file=open(r\"./drive/MyDrive/NLP_ass3/embedding_ids/e_ids.pkl\",\"rb\")\n","  evidence_ids=pickle.load(file)\n","\n","  output = {}\n","  for batch in tqdm(test_DataLoader):\n","    set_cuda(batch)\n","    # get the last hidden layer, detach the embedding from the logits\n","    q_outputs = model(input_ids=batch[\"query_input_ids\"], attention_mask=batch[\"query_attention_mask\"])\n","    q_logits = q_outputs.last_hidden_state\n","    q_embedding = q_logits[:, 0, :]\n","\n","    # transfer the q_embedding to cpu\n","    q_embedding_cpu = F.normalize(q_embedding).cpu()\n","    \n","    # get the evidences scores seperately and select the top ones\n","    similarity_scores = torch.mm(q_embedding_cpu, evidence_embeddings)\n","    batch_e_ids = torch.topk(similarity_scores, k=top_evidence, dim=1).indices.tolist()\n","\n","    for index, data in enumerate(batch[\"datas\"]):\n","      top_k_ids = batch_e_ids[index]\n","      data[\"evidences\"] = [evidence_ids[id] for id in top_k_ids]\n","      claim_id = batch[\"claim_ids\"][index]\n","      output[claim_id] = data\n","  fout = open(\"./drive/MyDrive/NLP_ass3/data/test-claims-retrieved.json\", 'w')\n","  json.dump(output, fout)\n","  fout.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SYNnFfJup46o","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1683114554716,"user_tz":-600,"elapsed":116089,"user":{"displayName":"Yixin Shen","userId":"08723041619229600532"}},"outputId":"7e0a5275-f1d3-457e-f2ad-2a554a0535d4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Finishing last run (ID:c0pax5my) before initializing another..."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">BERT</strong> at: <a href='https://wandb.ai/377188503/Task1%20Evidence%20Retrieval/runs/c0pax5my' target=\"_blank\">https://wandb.ai/377188503/Task1%20Evidence%20Retrieval/runs/c0pax5my</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_114643-c0pax5my/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Successfully finished last run (ID:c0pax5my). Initializing new run:<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_114717-2ojwsb8b</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/377188503/Task1%20Evidence%20Retrieval/runs/2ojwsb8b' target=\"_blank\">BERT</a></strong> to <a href='https://wandb.ai/377188503/Task1%20Evidence%20Retrieval' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/377188503/Task1%20Evidence%20Retrieval' target=\"_blank\">https://wandb.ai/377188503/Task1%20Evidence%20Retrieval</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/377188503/Task1%20Evidence%20Retrieval/runs/2ojwsb8b' target=\"_blank\">https://wandb.ai/377188503/Task1%20Evidence%20Retrieval/runs/2ojwsb8b</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 20/20 [00:07<00:00,  2.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evidence Retrieval F-score = 0.022\n","\n","##################################################Training##################################################\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 154/154 [00:38<00:00,  4.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["##################################################Evaluate##################################################\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:07<00:00,  2.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evidence Retrieval F-score = 0.000\n","\n","##################################################Training##################################################\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 154/154 [00:38<00:00,  4.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["##################################################Evaluate##################################################\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:06<00:00,  3.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evidence Retrieval F-score = 0.000\n","\n","##################################################Training##################################################\n"]},{"output_type":"stream","name":"stderr","text":["  4%|▍         | 6/154 [00:03<01:19,  1.85it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-aa46cad23b90>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevidence_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_evidence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# predict(model_name, batch_size, max_length, top_evidence, model_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-50-16443d15a292>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model_name, epoch, batch_size, max_length, evidence_samples, top_evidence, model_path)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0;31m# backward the loss, update the parameters in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m       \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Settings\n","epoch = 10\n","batch_size = 8\n","max_length = 128\n","evidence_samples = 64\n","model_path = \"\"\n","# TODO, adjust the top_evidence number\n","top_evidence = 3\n","# initialize the pretrained model\n","# TODO, use different pretrained model\n","model_name = \"bert-base-uncased\"\n","\n","train(model_name, epoch, batch_size, max_length, evidence_samples, top_evidence, model_path)\n","\n","# predict(model_name, batch_size, max_length, top_evidence, model_path)\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyODZSDHSkxIo6/UMS5H+KyM"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}