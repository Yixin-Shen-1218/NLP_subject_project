{"cells":[{"cell_type":"markdown","metadata":{"id":"n70dbH2mXuxp"},"source":["### Environment Preparation"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"F7Ssxo9Igssq","executionInfo":{"status":"ok","timestamp":1683626034963,"user_tz":-600,"elapsed":845,"user":{"displayName":"Yixin Shen","userId":"08723041619229600532"}}},"outputs":[],"source":["# code to set the python version to 3.8\n","# !sudo update-alternatives --config python3\n","# !python -V\n","# !sudo apt-get install python3-pip\n","# !python -m pip install --upgrade pip\n","# !pip install ipykernel"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29975,"status":"ok","timestamp":1683626066491,"user":{"displayName":"Yixin Shen","userId":"08723041619229600532"},"user_tz":-600},"id":"WYHmYN3f8yQH","outputId":"1ab49b70-1931-465c-abf5-4b593ae53f98"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.1+cu118)\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.15.2-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.22.2-py2.py3-none-any.whl (203 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.3/203.3 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Collecting setproctitle\n","  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Collecting GitPython!=3.1.29,>=1.0.0\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=4ba25b42a16cd58f01551c95d3c763618a69d2b4243fa3a80a20c310245bebb4\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built pathtools\n","Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.22.2 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.2\n"]}],"source":["!pip install torch torchvision transformers\n","!pip install wandb"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22400,"status":"ok","timestamp":1683626088888,"user":{"displayName":"Yixin Shen","userId":"08723041619229600532"},"user_tz":-600},"id":"JTD31p1S80Ch","outputId":"9b5a953f-e218-4a4a-df09-e04558bba271"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"dd7vn4_uKx2G","executionInfo":{"status":"ok","timestamp":1683626096292,"user_tz":-600,"elapsed":7405,"user":{"displayName":"Yixin Shen","userId":"08723041619229600532"}}},"outputs":[],"source":["from torch.utils.data import Dataset\n","import json\n","import random\n","from transformers import AutoTokenizer, AutoModel\n","import wandb\n","from torch.utils.data import DataLoader\n","from torch.nn import CrossEntropyLoss\n","from torch.optim import Adam\n","from torch import nn\n","import os\n","import torch\n","import numpy as np\n","from datetime import datetime\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"gXEAFZiyYCwv"},"source":["### CLS Model"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Lq-sbboCLECN","executionInfo":{"status":"ok","timestamp":1683626096293,"user_tz":-600,"elapsed":4,"user":{"displayName":"Yixin Shen","userId":"08723041619229600532"}}},"outputs":[],"source":["class CLS_Model(nn.Module):\n","    def __init__(self, model_name, dropout=0.5):\n","        super(CLS_Model, self).__init__()\n","        self.pretrained_model = AutoModel.from_pretrained(model_name)\n","        hidden_size = self.pretrained_model.config.hidden_size\n","\n","        self.cls_models = nn.Sequential(\n","            # nn.Dropout(dropout),\n","            nn.Linear(hidden_size, hidden_size),\n","            nn.Tanh(),\n","            nn.Linear(hidden_size, 4),\n","            nn.ReLU()\n","        )\n","\n","    def forward(self, input_ids, attn_mask):\n","        e_outputs = self.pretrained_model(input_ids=input_ids, attention_mask=attn_mask)\n","        e_logits = e_outputs.last_hidden_state\n","        cls_tokens = e_logits[:, 0, :]\n","        logits = self.cls_models(cls_tokens)\n","        return logits"]},{"cell_type":"markdown","metadata":{"id":"Tfo8gLg1YNEG"},"source":["### CLS Dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"3Xrbhh9081q0","executionInfo":{"status":"ok","timestamp":1683626096293,"user_tz":-600,"elapsed":4,"user":{"displayName":"Yixin Shen","userId":"08723041619229600532"}}},"outputs":[],"source":["# function to merge two dictionaries\n","def Merge(dict1, dict2):\n","    res = {**dict1, **dict2}\n","    return res"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"CnhqNjtxBRHs","executionInfo":{"status":"ok","timestamp":1683626096293,"user_tz":-600,"elapsed":3,"user":{"displayName":"Yixin Shen","userId":"08723041619229600532"}}},"outputs":[],"source":["class CLSDataset(Dataset):\n","    def __init__(self, mode, tokenizer, label_dic, max_length):\n","        self.mode = mode\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","        # use both the train and dev datasets to train the model\n","        if mode == \"train_dev\":\n","            f = open(\"./drive/MyDrive/NLP_ass3/data/train-claims.json\", \"r\")\n","            train_dataset = json.load(f)\n","            f.close()\n","\n","            f = open(\"./drive/MyDrive/NLP_ass3/data/dev-claims.json\", \"r\")\n","            dev_dataset = json.load(f)\n","            f.close()\n","\n","            self.dataset = Merge(train_dataset, dev_dataset)\n","        elif mode == \"test\":\n","            f = open(\"./drive/MyDrive/NLP_ass3/predict/v1/test-claims-retrieved.json\", \"r\")\n","            self.dataset = json.load(f)\n","            f.close()\n","        else:\n","            # open the train/dev file\n","            f = open(\"./drive/MyDrive/NLP_ass3/data/{}-claims.json\".format(mode), \"r\")\n","            self.dataset = json.load(f)\n","            f.close()\n","        self.claim_ids = list(self.dataset.keys())\n","\n","        # open the evidence file\n","        f = open(\"./drive/MyDrive/NLP_ass3/data/evidence.json\", \"r\")\n","        self.evidences = json.load(f)\n","        f.close()\n","        self.evidence_ids = list(self.evidences.keys())\n","\n","        self.label_dic = label_dic\n","\n","    def __len__(self):\n","        return len(self.claim_ids)\n","\n","    def __getitem__(self, index):\n","        claim_id = self.claim_ids[index]\n","        data = self.dataset[claim_id]\n","        input_list = []\n","        claim = data[\"claim_text\"].lower()\n","        input_list.append(claim)\n","\n","        # add evidences to the list\n","        for e_id in data[\"evidences\"]:\n","            evidence = self.evidences[e_id].lower()\n","            input_list.append(evidence)\n","\n","        # add [SEP] tokens between the texts\n","        input_text = \"\"\n","        for idx, text in enumerate(input_list):\n","            if idx == 0:\n","                input_text = text\n","            else:\n","                input_text = input_text + \"[SEP]\" + text\n","        if self.mode != \"test\":\n","          label = self.label_dic[data[\"claim_label\"]]\n","        else:\n","          label = None\n","        return [input_text, label, data, claim_id]\n","\n","    def collate_fn(self, batch):\n","        inputs = []\n","        labels = []\n","        datas = []\n","        claim_ids = []\n","\n","        for item in batch:\n","            inputs.append(item[0])\n","            labels.append(item[1])\n","            datas.append(item[2])\n","            claim_ids.append(item[3])\n","\n","        input_texts_tokens = self.tokenizer(\n","            inputs,\n","            max_length=self.max_length,\n","            padding=True,\n","            truncation=True,\n","            return_tensors=\"pt\"\n","        )\n","\n","        encoding_dict = {\n","            \"text_input_ids\": input_texts_tokens[\"input_ids\"],\n","            \"text_attn_mask\": input_texts_tokens[\"attention_mask\"],\n","            \"datas\": datas,\n","            \"claims_ids\": claim_ids\n","        }\n","\n","        if self.mode != \"test\":\n","            encoding_dict[\"label\"] = torch.LongTensor(labels)\n","\n","        return encoding_dict"]},{"cell_type":"markdown","metadata":{"id":"Bbp4lhNeYRcY"},"source":["### Auxiliary Functions"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ePbwJhvqRKaq","executionInfo":{"status":"ok","timestamp":1683626096293,"user_tz":-600,"elapsed":3,"user":{"displayName":"Yixin Shen","userId":"08723041619229600532"}}},"outputs":[],"source":["# set up the seed\n","def setup_seed(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"a_ahg-L5I6pN","executionInfo":{"status":"ok","timestamp":1683626096293,"user_tz":-600,"elapsed":3,"user":{"displayName":"Yixin Shen","userId":"08723041619229600532"}}},"outputs":[],"source":["# put batch to device\n","def set_cuda(batch):\n","    for key in batch.keys():\n","        if key in [\"text_input_ids\", \"text_attn_mask\", \"label\"]:\n","            # print(batch[key])\n","            # print(device)\n","            # print(batch[key].type)\n","            # print(batch[key].is_cuda)\n","            batch[key] = batch[key].cuda()"]},{"cell_type":"markdown","metadata":{"id":"mVY8LvSFY4eA"},"source":["### Crucial Functions"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"t3oxC2RRI8vn","executionInfo":{"status":"ok","timestamp":1683626096294,"user_tz":-600,"elapsed":4,"user":{"displayName":"Yixin Shen","userId":"08723041619229600532"}}},"outputs":[],"source":["def evaluate(cls_model, val_dataloader, epoch_num):\n","    # set model to evaluate mode\n","    cls_model.eval()\n","    all_count = 0\n","    correct_count = 0\n","\n","    for batch in tqdm(val_dataloader):\n","        set_cuda(batch)\n","        logits = CLS_Model.forward(cls_model, input_ids=batch[\"text_input_ids\"], attn_mask=batch[\"text_attn_mask\"])\n","        predictions = logits.argmax(-1).tolist()\n","\n","        # accumulate the correct count number\n","        for idx, prediction in enumerate(predictions):\n","            if prediction == batch[\"label\"][idx]:\n","                correct_count += 1\n","\n","        all_count += len(predictions)\n","\n","    accuracy = correct_count / all_count\n","    print(\"\\nThis is epoch\", epoch_num, \", the accuracy =\", accuracy)\n","\n","    # set model to train mode\n","    cls_model.train()\n","    return accuracy\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"J9jbdi1SI_5U","executionInfo":{"status":"ok","timestamp":1683626096294,"user_tz":-600,"elapsed":4,"user":{"displayName":"Yixin Shen","userId":"08723041619229600532"}}},"outputs":[],"source":["def train(model_name, epochs, batch_size, max_length, model_path):\n","    # initiate the wandb\n","    wandb.init(project=\"Task2 Text Classification\", name=\"CLS_Bert_without_dropout\")\n","\n","    setup_seed(42)\n","    # create the folder to save the model trained\n","    month_date = datetime.now().strftime(\"%m-%d\")\n","    checkpoints_dir_path = f\"./drive/MyDrive/NLP_ass3/CLS_checkpoints/{month_date}\"\n","    if not os.path.exists(checkpoints_dir_path):\n","        os.makedirs(checkpoints_dir_path)\n","\n","    # initialize the pretrained model\n","    CLS_model = CLS_Model(model_name, dropout=0.5)\n","    if model_path != \"\":\n","        CLS_model.load_state_dict(torch.load(os.path.join(\"./drive/MyDrive/NLP_ass3/CLS_checkpoints\", model_path, \"best_state_dict.bin\")))\n","\n","    # use GPU to train the model\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    # print(device)\n","    CLS_model.to(device)\n","    CLS_model.train()\n","\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","    # transform label to num\n","    label_dic = {\"SUPPORTS\": 0, \"REFUTES\": 1, \"NOT_ENOUGH_INFO\": 2, \"DISPUTED\": 3}\n","\n","    train_Dataset = CLSDataset(\"train_dev\", tokenizer, label_dic, max_length)\n","    val_Dataset = CLSDataset(\"dev\", tokenizer, label_dic, max_length)\n","\n","    train_DataLoader = DataLoader(train_Dataset, batch_size=batch_size, shuffle=True, num_workers=4,\n","                                  collate_fn=train_Dataset.collate_fn)\n","    val_DataLoader = DataLoader(val_Dataset, batch_size=batch_size, shuffle=False, num_workers=4,\n","                                collate_fn=val_Dataset.collate_fn)\n","\n","    Loss_Function = CrossEntropyLoss()\n","    optimizer = Adam(CLS_model.parameters(), lr=2e-5)\n","\n","    # set some counter for training\n","    update_count = 0\n","    avg_loss = 0\n","    max_accuracy = 0\n","    epoch_num = 0\n","\n","    for epoch in range(epochs):\n","        print(\"########################################Training########################################\")\n","        for (idx, batch) in enumerate(tqdm(train_DataLoader)):\n","            # start training\n","            optimizer.zero_grad()\n","\n","            # put the data in batch into cuda\n","            set_cuda(batch)\n","\n","            # calculate the loss and do the back propagation\n","            logits = CLS_Model.forward(CLS_model, input_ids=batch[\"text_input_ids\"], attn_mask=batch[\"text_attn_mask\"])\n","            loss = Loss_Function(logits, batch[\"label\"])\n","            loss.backward()\n","            avg_loss += loss.item()\n","\n","            #  update the optimizer\n","            optimizer.step()\n","\n","            update_count += 1\n","\n","            wandb_freq = 20\n","            if update_count % wandb_freq == 0:\n","                wandb.log({\"loss\": avg_loss / wandb_freq}, step=update_count)\n","                avg_loss = 0\n","\n","        print(\"########################################Evaluate########################################\")\n","        # finish one epoch, add one to the epoch_num\n","        epoch_num += 1\n","        # evaluate the model every epoch and save the best one that have the best f_score\n","        accuracy = evaluate(CLS_model, val_DataLoader, epoch_num)\n","        wandb.log({\"accuracy\": accuracy}, step=update_count)\n","\n","        if accuracy > max_accuracy:\n","            max_accuracy = accuracy\n","            torch.save(CLS_model.state_dict(), os.path.join(checkpoints_dir_path, \"best_state_dict.bin\"))\n","            print(\"\\nThis is the\", epoch_num, \"epoch\", \"the max acc is\", max_accuracy)\n","\n","\n","    # finish the wandb\n","    wandb.finish()"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"LS2DFVlCaovR","executionInfo":{"status":"ok","timestamp":1683626096294,"user_tz":-600,"elapsed":4,"user":{"displayName":"Yixin Shen","userId":"08723041619229600532"}}},"outputs":[],"source":["def predict(model_name, batch_size, max_length, model_path):\n","    # initialize the pretrained model\n","    CLS_model = CLS_Model(model_name, dropout=0.5)\n","\n","    label_dic = {\"SUPPORTS\": 0, \"REFUTES\": 1, \"NOT_ENOUGH_INFO\": 2, \"DISPUTED\": 3}\n","    label_list = [\"SUPPORTS\", \"REFUTES\", \"NOT_ENOUGH_INFO\", \"DISPUTED\"]\n","\n","    assert model_path\n","    CLS_model.load_state_dict(torch.load(os.path.join(\"./drive/MyDrive/NLP_ass3/CLS_checkpoints\", model_path, \"best_state_dict.bin\")))\n","\n","    # use GPU to train the model and set the model mode to evaluate\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    # print(device)\n","    CLS_model.to(device)\n","    CLS_model.eval()\n","\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","    test_Dataset = CLSDataset(\"test\", tokenizer, label_dic, max_length)\n","    test_DataLoader = DataLoader(test_Dataset, batch_size=batch_size, shuffle=False, num_workers=4, collate_fn=test_Dataset.collate_fn)\n","\n","    # generate the output\n","    output = {}\n","    for batch in tqdm(test_DataLoader):\n","      set_cuda(batch)\n","      logits = CLS_Model.forward(CLS_model, input_ids=batch[\"text_input_ids\"], attn_mask=batch[\"text_attn_mask\"])\n","      predictions = logits.argmax(-1).tolist()\n","      \n","      for idx, data in enumerate(batch[\"datas\"]):\n","        prediction = predictions[idx]\n","        data[\"claim_label\"] = label_list[prediction]\n","        claim_id = batch[\"claims_ids\"][idx]\n","        output[claim_id] = data\n","\n","    fout = open(\"./drive/MyDrive/NLP_ass3/data/test-claims-predictions.json\", 'w')\n","    json.dump(output, fout)\n","    fout.close()\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"KVaVZV3PJCnn","executionInfo":{"status":"ok","timestamp":1683626097849,"user_tz":-600,"elapsed":2,"user":{"displayName":"Yixin Shen","userId":"08723041619229600532"}}},"outputs":[],"source":["def main():\n","    # settings of the model\n","    model_name = \"bert-base-uncased\"\n","    # model_name = \"roberta-base\"\n","    epochs = 10\n","    batch_size = 8\n","    # max_length = 512\n","    max_length = 512\n","    model_path = \"\"\n","\n","    train(model_name, epochs, batch_size, max_length, model_path)\n","\n","    # predict(model_name, batch_size, max_length, model_path)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":476,"referenced_widgets":["6645fce2c8484027a482736b0ead714f","f0384f0c950f4831a9fa5a9e1420cdea","5d1230eaf11d41e49295d09d21a666d8","e8f6fbaa27384040b11ac5a6d62e8e55","c4f9121fc96b4b42bad30ba74ce84244","324fafb96d1e44928ff71c278c461797","e73ceb9c86214805926c28c43862a1ab","8d7ce77c7b434cccafde253746609dba"]},"id":"C--zne39JGwI","outputId":"dc569211-7126-4ee9-8585-c7354ac68c11","executionInfo":{"status":"error","timestamp":1683626906404,"user_tz":-600,"elapsed":63642,"user":{"displayName":"Yixin Shen","userId":"08723041619229600532"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m377188503\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666987836667128, max=1.0)…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6645fce2c8484027a482736b0ead714f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Problem at: <ipython-input-11-ef20f1e3aeb5> 3 train\n"]},{"output_type":"error","ename":"CommError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-263240bbee7e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-13-b396bd852d61>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# predict(model_name, batch_size, max_length, model_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-ef20f1e3aeb5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model_name, epochs, batch_size, max_length, model_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# initiate the wandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Task2 Text Classification\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CLS_Bert_without_dropout\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msetup_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m             \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    767\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mrun_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# for mypy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mCommError\u001b[0m: Run initialization has timed out after 60.0 sec. \nPlease refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-"]}],"source":["main()"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPkVW7mR5WTl4r8nPgSzC4j"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6645fce2c8484027a482736b0ead714f":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_f0384f0c950f4831a9fa5a9e1420cdea","IPY_MODEL_5d1230eaf11d41e49295d09d21a666d8"],"layout":"IPY_MODEL_e8f6fbaa27384040b11ac5a6d62e8e55"}},"f0384f0c950f4831a9fa5a9e1420cdea":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4f9121fc96b4b42bad30ba74ce84244","placeholder":"​","style":"IPY_MODEL_324fafb96d1e44928ff71c278c461797","value":"Waiting for wandb.init()...\r"}},"5d1230eaf11d41e49295d09d21a666d8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e73ceb9c86214805926c28c43862a1ab","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8d7ce77c7b434cccafde253746609dba","value":0.9844676191166702}},"e8f6fbaa27384040b11ac5a6d62e8e55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4f9121fc96b4b42bad30ba74ce84244":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"324fafb96d1e44928ff71c278c461797":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e73ceb9c86214805926c28c43862a1ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d7ce77c7b434cccafde253746609dba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}