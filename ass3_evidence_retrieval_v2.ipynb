{"cells":[{"cell_type":"markdown","source":["### Environment Preparation"],"metadata":{"id":"1w8rlJ7BMXf9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3L4-aZo03uQz"},"outputs":[],"source":["# code to set the python version to 3.8\n","# !sudo update-alternatives --config python3\n","# !python -V\n","# !sudo apt-get install python3-pip\n","# !python -m pip install --upgrade pip\n","# !pip install ipykernel"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQjp6qejYfuW","executionInfo":{"status":"ok","timestamp":1683291128561,"user_tz":-600,"elapsed":16196,"user":{"displayName":"Yixin Shen","userId":"08723041619229600532"}},"outputId":"7ffb9415-c05b-4032-8c3c-1ebdcc7f939b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.1+cu118)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Using cached wandb-0.15.1-py3-none-any.whl (2.0 MB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n","Collecting GitPython!=3.1.29,>=1.0.0\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting setproctitle\n","  Using cached setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Collecting sentry-sdk>=1.0.0\n","  Using cached sentry_sdk-1.22.0-py2.py3-none-any.whl (203 kB)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Collecting pathtools\n","  Using cached pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=57acefac9d13473e377bae99b4c9a831d03d6d6f336953522e43dd6456ffda50\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built pathtools\n","Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.22.0 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.1\n"]}],"source":["!pip install torch torchvision transformers\n","!pip install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KHo9cD6v4zJX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683291132192,"user_tz":-600,"elapsed":3635,"user":{"displayName":"Yixin Shen","userId":"08723041619229600532"}},"outputId":"273de601-b8aa-48ec-ad76-7264709fcf40"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","import json\n","import random\n","from tqdm import tqdm\n","import torch.nn.functional as F\n","import torch\n","import numpy as np\n","from datetime import datetime\n","from transformers import AutoTokenizer, AutoModel\n","import wandb\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","import os\n","import torch.nn as nn"],"metadata":{"id":"prJUeEfRKfCH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Evidence Retrieval Dataset"],"metadata":{"id":"9n3Xh5MuMbry"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BRtUbg9XqC_6"},"outputs":[],"source":["# function to merge two dictionaries\n","def Merge(dict1, dict2):\n","    res = {**dict1, **dict2}\n","    return res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m2xLzntt5g6z"},"outputs":[],"source":["# Process the training dataset\n","class TrainDataset(Dataset):\n","  def __init__(self, mode, tokenizer, evidence_samples, max_length):\n","    self.mode = mode\n","    self.tokenizer = tokenizer\n","    self.evidence_samples = evidence_samples\n","    self.max_length = max_length\n","    \n","    # use both the train and dev datasets to train the model\n","    if mode == \"train_dev\":\n","      f = open(\"./drive/MyDrive/NLP_ass3/data/train-claims.json\", \"r\")\n","      train_dataset = json.load(f)\n","      f.close()\n","\n","      f = open(\"./drive/MyDrive/NLP_ass3/data/dev-claims.json\", \"r\")\n","      dev_dataset = json.load(f)\n","      f.close()\n","\n","      self.dataset = Merge(train_dataset, dev_dataset)\n","    else:\n","      # open the train/dev file\n","      f = open(\"./drive/MyDrive/NLP_ass3/data/{}-claims.json\".format(mode), \"r\")\n","      self.dataset = json.load(f)\n","      f.close()\n","    self.claim_ids = list(self.dataset.keys())\n","    \n","    # open the evidence file \n","    f = open(\"./drive/MyDrive/NLP_ass3/data/evidence.json\", \"r\")\n","    self.evidences = json.load(f)\n","    f.close()\n","    self.evidence_ids = list(self.evidences.keys())\n","\n","  def __len__(self):\n","    return len(self.claim_ids)\n","\n","  def __getitem__(self, index):\n","    claim_id = self.claim_ids[index]\n","    data = self.dataset[claim_id]\n","    processed_query = data[\"claim_text\"].lower()\n","    evidences = []\n","    for evidence_id in data[\"evidences\"]:\n","      evidences.append(evidence_id)\n","    return [processed_query, evidences]\n","\n","  def collate_fn(self, batch):\n","    queries = []\n","    evidences = []\n","    answer_lens = []\n","    for query, evidence in batch:\n","      queries.append(query)\n","      evidences.extend(evidence)\n","      answer_lens.append(len(evidence))\n","    \n","    # set some negative example for training\n","    evidence_num = len(evidences)\n","    # if the number of evidence is larger than example setting, trancate the evidence list\n","    if evidence_num > self.evidence_samples:\n","      evidences = evidences[:self.evidence_samples]\n","\n","    # if the number of evidence is less than example setting,\n","    # randomly choose evidence from the dataset while proving there is no duplication\n","    evidences_text = [self.evidences[evidence_id].lower() for evidence_id in evidences]\n","    while evidence_num < self.evidence_samples:\n","      evidence_id = random.choice(self.evidence_ids)\n","      while evidence_id in evidences:\n","        evidence_id = random.choice(self.evidence_ids)\n","      evidences.append(evidence_id)\n","      evidences_text.append(self.evidences[evidence_id].lower())\n","      evidence_num += 1\n","\n","    query_text_token = self.tokenizer(\n","        queries,\n","        max_length=self.max_length,\n","        padding=True,\n","        truncation=True,\n","        return_tensors=\"pt\"\n","    )\n","\n","    evidences_text_token = self.tokenizer(\n","        evidences_text,\n","        max_length=self.max_length,\n","        padding=True,\n","        truncation=True,\n","        return_tensors=\"pt\"\n","    )\n","\n","    encoding_dict = {\"query_input_ids\" : query_text_token[\"input_ids\"],\n","            \"evidence_input_ids\" : evidences_text_token[\"input_ids\"],\n","            \"query_attention_mask\" : query_text_token[\"attention_mask\"],\n","            \"evidence_attention_mask\" : evidences_text_token[\"attention_mask\"],\n","            \"answer_lens\" : answer_lens}\n","    return encoding_dict\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AQykm8PdovGY"},"outputs":[],"source":["# Process the validate dataset\n","class ValidateDataset(Dataset):\n","  def __init__(self, mode, tokenizer, max_length):\n","    self.tokenizer = tokenizer\n","    self.mode = mode\n","    self.max_length = max_length\n","\n","    # open the dev/test file\n","    if mode != \"test\":\n","      f = open(\"./drive/MyDrive/NLP_ass3/data/{}-claims.json\".format(mode), \"r\")\n","    else:\n","      f = open(\"./drive/MyDrive/NLP_ass3/data/test-claims-unlabelled.json\", \"r\")\n","\n","    self.dataset = json.load(f)\n","    f.close()\n","\n","    # read the claim ids to a list\n","    self.claim_ids = list(self.dataset.keys())\n","\n","  def __len__(self):\n","    return len(self.claim_ids)\n","  \n","  def __getitem__(self, index):\n","    claim_id = self.claim_ids[index]\n","    data = self.dataset[claim_id]\n","    processed_query = data[\"claim_text\"].lower()\n","    return [processed_query, data, claim_id]\n","\n","  def collate_fn(self, batch):\n","    queries = []\n","    datas = []\n","    claim_ids = []\n","    evidences = []\n","    # print(\"read the dev file 1111\")\n","\n","    for query, data, claim_id in batch:\n","      queries.append(query)\n","      datas.append(data)\n","      claim_ids.append(claim_id)\n","      if self.mode != \"test\":\n","        evidences.append(data[\"evidences\"])\n","\n","    # print(\"read the dev file\")\n","\n","    query_text_token = self.tokenizer(\n","      queries,\n","      max_length=self.max_length,\n","      padding=True,\n","      truncation=True,\n","      return_tensors=\"pt\"\n","    )\n","\n","    encoding_dict = {\"query_input_ids\" : query_text_token[\"input_ids\"],\n","              \"query_attention_mask\" : query_text_token[\"attention_mask\"],\n","              \"datas\" : datas,\n","              \"claim_ids\" : claim_ids}\n","    # if the file is dev, encode the evidences into the encodings\n","    if self.mode != \"test\":\n","      encoding_dict[\"evidences\"] = evidences\n","    return encoding_dict\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z7yVpCrjoyow"},"outputs":[],"source":["# Process the evidence dataset\n","class EvidenceDataset(Dataset):\n","  def __init__(self, tokenizer, max_length):\n","    self.tokenizer = tokenizer\n","    self.max_length = max_length\n","\n","    f = open(\"./drive/MyDrive/NLP_ass3/data/evidence.json\", \"r\")\n","    self.evidences = json.load(f)\n","    f.close()\n","\n","    self.evidences_ids = list(self.evidences.keys())\n","\n","  def __len__(self):\n","    return len(self.evidences_ids)\n","\n","  def __getitem__(self, index):\n","    evidences_id = self.evidences_ids[index]\n","    evidence = self.evidences[evidences_id]\n","    return [evidences_id, evidence]\n","    \n","  def collate_fn(self, batch):\n","    evidences_ids = []\n","    evidences = []\n","\n","    for evidences_id, evidence in batch:\n","      evidences_ids.append(evidences_id)\n","      evidences.append(evidence.lower())\n","\n","    evidences_text_token = self.tokenizer(\n","        evidences,\n","        max_length=self.max_length,\n","        padding=True,\n","        truncation=True,\n","        return_tensors=\"pt\"\n","    )\n","\n","    encoding_dict = {\"evidence_input_ids\" : evidences_text_token[\"input_ids\"],\n","               \"evidence_attention_mask\" : evidences_text_token[\"attention_mask\"],\n","               \"evidences_ids\" : evidences_ids}\n","\n","    return encoding_dict"]},{"cell_type":"markdown","source":["### Auxiliary Functions"],"metadata":{"id":"TgG91_eRMfBI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rBzWC5B0yZWU"},"outputs":[],"source":["def set_cuda(batch):\n","  for key in batch.keys():\n","    if key in [\"query_input_ids\", \"evidence_input_ids\", \"query_attention_mask\", \"evidence_attention_mask\"]:\n","      batch[key] = batch[key].cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-6eSLtEnZ_K3"},"outputs":[],"source":["# function to set the random seed\n","def setup_seed(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)"]},{"cell_type":"markdown","source":["### Crucial Functions"],"metadata":{"id":"YzMYNwoPMpCp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"LJqIVpOAgQNL"},"outputs":[],"source":["# the function to get the evidence embeddings\n","def embed_evidence(evidence_DataLoader, model):\n","  # set the model to evaluate mode\n","  model.eval()\n","  e_embeddings = []\n","  e_ids = []\n","  for batch in tqdm(evidence_DataLoader):\n","    set_cuda(batch)\n","    # get the last hidden layer, detach the embedding from the logits\n","    e_outputs = model(input_ids=batch[\"evidence_input_ids\"], attention_mask=batch[\"evidence_attention_mask\"])\n","    e_logits = e_outputs.last_hidden_state\n","    e_embedding = e_logits[:, 0, :].detach()\n","\n","    # transfer the e_embedding to cpu\n","    e_embedding_cpu = F.normalize(e_embedding).cpu()\n","    del e_logits, e_embedding\n","\n","    # append the data to list\n","    e_embeddings.append(e_embedding_cpu)\n","    e_ids.extend(batch[\"evidences_ids\"])\n","\n","  e_embeddings = torch.cat(e_embeddings, dim=0).t()\n","  return e_embeddings, e_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oCxfvQRMw8IN"},"outputs":[],"source":["def evaluate(val_DataLoader, evidence_embeddings, evidence_ids, model, top_evidence):\n","  f_scores = []\n","  for batch in tqdm(val_DataLoader):\n","    set_cuda(batch)\n","    # get the last hidden layer, detach the embedding from the logits\n","    q_outputs = model(input_ids=batch[\"query_input_ids\"], attention_mask=batch[\"query_attention_mask\"])\n","    q_logits = q_outputs.last_hidden_state\n","    q_embedding = q_logits[:, 0, :]\n","\n","    # transfer the q_embedding to cpu\n","    q_embedding_cpu = F.normalize(q_embedding).cpu()\n","    \n","    # get the evidences scores seperately and select the top ones\n","    similarity_scores = torch.mm(q_embedding_cpu, evidence_embeddings)\n","    batch_e_ids = torch.topk(similarity_scores, k=top_evidence, dim=1).indices.tolist()\n","\n","    for index, data in enumerate(batch[\"datas\"]):\n","        top_k_ids = batch_e_ids[index]\n","        top_e_ids = [evidence_ids[id] for id in top_k_ids]\n","        correct_evidence = [e_id for e_id in batch[\"evidences\"][index] if e_id in top_e_ids]\n","        \n","        if len(correct_evidence) > 0:\n","            recall = len(correct_evidence) / len(batch[\"evidences\"][index])\n","            precision = len(correct_evidence) / len(top_e_ids)\n","            f_score = (2 * precision * recall) / (precision + recall)\n","        else:\n","            f_score = 0\n","        f_scores.append(f_score)\n","\n","  f_socre_final = np.mean(f_scores)\n","  print(\"\\nEvidence Retrieval F-score = %.3f\\n\" % f_socre_final)\n","\n","  # set the model back to train mode\n","  model.train()\n","\n","  return f_socre_final"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R1Hdk358P0dr"},"outputs":[],"source":["def train(model_name, epoch, batch_size, max_length, evidence_samples, top_evidence, model_path):\n","  # initiate the wandb\n","  wandb.init(project=\"Task1 Evidence Retrieval\", name=\"DPR_v2_roberta-base_DifferentLR\")\n","\n","  # set the random seed of the model\n","  setup_seed(42)\n","\n","  # create the folder to save the model trained  \n","  month_date = datetime.now().strftime(\"%m-%d\")\n","  checkpoints_dir_path = f\"./drive/MyDrive/NLP_ass3/checkpoints_v2/{month_date}\"\n","  if not os.path.exists(checkpoints_dir_path):\n","    os.makedirs(checkpoints_dir_path)\n","  \n","  # initialize the pretrained model\n","  query_model = AutoModel.from_pretrained(model_name)\n","  evidence_model = AutoModel.from_pretrained(model_name)\n","\n","  if model_path != \"\":\n","      query_model.load_state_dict(torch.load(os.path.join(\"./drive/MyDrive/NLP_ass3/checkpoints_v2\", model_path, \"best_query.bin\")))\n","      evidence_model.load_state_dict(torch.load(os.path.join(\"./drive/MyDrive/NLP_ass3/checkpoints_v2\", model_path, \"best_evidence.bin\")))\n","\n","\n","  # use GPU to train the model\n","  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","  # print(device)\n","  query_model.to(device)\n","  evidence_model.to(device)\n","  # set model to train mode\n","  query_model.train()\n","  evidence_model.train()\n","\n","  # get the tokenizer from the specific model\n","  tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","  # initialize the datasets and read to the DataLoader for feeding into the model\n","  train_dataset = TrainDataset(\"train\", tokenizer, evidence_samples, max_length)\n","  val_dataset = ValidateDataset(\"dev\", tokenizer, max_length)\n","  evidence_dataset = EvidenceDataset(tokenizer, max_length)\n","\n","  train_DataLoader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, collate_fn=train_dataset.collate_fn)\n","  val_DataLoader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=8, collate_fn=val_dataset.collate_fn)\n","  evidence_DataLoader = DataLoader(evidence_dataset, batch_size=128, shuffle=False, num_workers=8, collate_fn=evidence_dataset.collate_fn)\n","\n","  # TODO: here to change the optimizer\n","  # TODO: adjust the lr\n","  query_optimizer = optim.Adam(query_model.parameters(), lr=2e-5)\n","  evidence_optimizer = optim.Adam(evidence_model.parameters(), lr=2e-5)\n","  query_scheduler = torch.optim.lr_scheduler.StepLR(query_optimizer, step_size=50, gamma=0.9, last_epoch=-1)\n","  evidence_scheduler = torch.optim.lr_scheduler.StepLR(evidence_optimizer, step_size=50, gamma=0.9, last_epoch=-1)\n","\n","\n","  # set some counter for training\n","  update_count = 0\n","  avg_loss = 0\n","  max_f_score = 0\n","  epoch_num = 0\n","\n","  # get the evidence embedding for scoring\n","  evidence_embeddings, evidence_ids = embed_evidence(evidence_DataLoader, evidence_model)\n","  f_score = evaluate(val_DataLoader, evidence_embeddings, evidence_ids, query_model, top_evidence)\n","  wandb.log({\"f_score\": f_score}, step=update_count)\n","\n","  # assign the f_score to max_f_score\n","  max_f_score = f_score\n","  \n","  for epoch in range(epoch):\n","    print(\"##################################################Training##################################################\")\n","    # use to save the count of epoch update step\n","    for (idx, batch) in enumerate(tqdm(train_DataLoader)):\n","      # start training\n","      query_optimizer.zero_grad()\n","      evidence_optimizer.zero_grad()\n","      \n","      # put the data in batch into cuda\n","      set_cuda(batch)\n","\n","      # get the embeddings of the q and e according \n","      q_outputs = query_model(input_ids=batch[\"query_input_ids\"], attention_mask=batch[\"query_attention_mask\"])\n","      q_logits = q_outputs.last_hidden_state\n","\n","      e_outputs = evidence_model(input_ids=batch[\"evidence_input_ids\"], attention_mask=batch[\"evidence_attention_mask\"])\n","      e_logits = e_outputs.last_hidden_state\n","      \n","      q_embeddings = q_logits[:, 0, :]\n","      e_embeddings = e_logits[:, 0, :]\n","\n","      # normalize the embeddings\n","      q_embeddings = F.normalize(q_embeddings)\n","      e_embeddings = F.normalize(e_embeddings)\n","\n","      # calculate the cosine similarity between the queries and evidences\n","      cos_similarities = torch.mm(q_embeddings, e_embeddings.t())\n","      # prevent overflow, accelarate back propogation\n","      log_soft_scores = - F.log_softmax(cos_similarities * 50, dim=1)\n","\n","      loss_list = []\n","      start_index = 0\n","      for index, answer_len in enumerate(batch[\"answer_lens\"]):\n","        end_index = start_index + answer_len\n","        current_loss = torch.mean(log_soft_scores[index, start_index:end_index])\n","        loss_list.append(current_loss)\n","        start_index = end_index\n","\n","      loss = torch.stack(loss_list).mean()\n","      \n","      # backward the loss, update the parameters in the model\n","      loss.backward()\n","      avg_loss = avg_loss + loss.item()\n","\n","      # mitigate the problem of exploding gradients\n","      nn.utils.clip_grad_norm_(query_model.parameters(), 1)\n","      nn.utils.clip_grad_norm_(evidence_model.parameters(), 1)\n","      \n","      # optimize the model and lr\n","      query_optimizer.step()\n","      evidence_optimizer.step()\n","      query_scheduler.step()\n","      evidence_scheduler.step()\n","\n","\n","      update_count += 1\n","\n","      wandb_freq = 20\n","      if update_count % wandb_freq == 0:\n","        wandb.log({\"loss\": avg_loss / wandb_freq}, step=update_count)\n","        avg_loss = 0\n","\n","      del loss, cos_similarities, q_embeddings, e_embeddings\n","\n","    print(\"##################################################Evaluate##################################################\")\n","    # finish one epoch, add one to the epoch_num\n","    epoch_num += 1\n","    # evaluate the model every epoch and save the best one that have the best f_score\n","    evidence_embeddings, evidence_ids = embed_evidence(evidence_DataLoader, evidence_model)\n","    f_score = evaluate(val_DataLoader, evidence_embeddings, evidence_ids, query_model, top_evidence)\n","    wandb.log({\"f_score\": f_score}, step=update_count)\n","\n","    if f_score > max_f_score:\n","      max_f_score = f_score\n","      torch.save(query_model.state_dict(), os.path.join(checkpoints_dir_path, \"best_query.bin\"))\n","      torch.save(evidence_model.state_dict(), os.path.join(checkpoints_dir_path, \"best_evidence.bin\"))\n","      print(\"\\nThis is the\", epoch_num, \"epoch\", \"the max f_score is\", max_f_score)\n","  # finish the wandb\n","  wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SchJbuxhRgoH"},"outputs":[],"source":["def predict(model_name, batch_size, max_length, top_evidence, model_path):\n","  # get the tokenizer from the specific model\n","  tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","  # initialize the pretrained model\n","  query_model = AutoModel.from_pretrained(model_name)\n","  evidence_model = AutoModel.from_pretrained(model_name)\n","\n","  # load the best finetuned parameters\n","  assert model_path\n","  # print(os.path.join(\"./drive/MyDrive/NLP_ass3/checkpoints_v2\", model_path, \"best_state_dict.bin\"))\n","  query_model.load_state_dict(torch.load(os.path.join(\"./drive/MyDrive/NLP_ass3/checkpoints_v2\", model_path, \"best_query.bin\")))\n","  evidence_model.load_state_dict(torch.load(os.path.join(\"./drive/MyDrive/NLP_ass3/checkpoints_v2\", model_path, \"best_evidence.bin\")))\n","\n","  # use GPU, and set the model to evaluate mode\n","  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","  # print(device)\n","  query_model.to(device)\n","  evidence_model.to(device)\n","\n","  query_model.eval()\n","  evidence_model.eval()\n","\n","  # load the test and evidence datasets\n","  test_dataset = ValidateDataset(\"test\", tokenizer, max_length)\n","  evidence_dataset = EvidenceDataset(tokenizer, max_length)\n","\n","  test_DataLoader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8, collate_fn=test_dataset.collate_fn)\n","  evidence_DataLoader = DataLoader(evidence_dataset, batch_size=128, shuffle=False, num_workers=8, collate_fn=evidence_dataset.collate_fn)\n","\n","\n","  # utilize embed_evidence function to get the evidences embeddings\n","  evidence_embeddings, evidence_ids = embed_evidence(evidence_DataLoader, evidence_model)\n","\n","  output = {}\n","  for batch in tqdm(test_DataLoader):\n","    set_cuda(batch)\n","    # get the last hidden layer, detach the embedding from the logits\n","    q_outputs = query_model(input_ids=batch[\"query_input_ids\"], attention_mask=batch[\"query_attention_mask\"])\n","    q_logits = q_outputs.last_hidden_state\n","    q_embedding = q_logits[:, 0, :]\n","\n","    # transfer the q_embedding to cpu\n","    q_embedding_cpu = F.normalize(q_embedding).cpu()\n","    \n","    # get the evidences scores seperately and select the top ones\n","    similarity_scores = torch.mm(q_embedding_cpu, evidence_embeddings)\n","    batch_e_ids = torch.topk(similarity_scores, k=top_evidence, dim=1).indices.tolist()\n","\n","    for index, data in enumerate(batch[\"datas\"]):\n","      top_k_ids = batch_e_ids[index]\n","      data[\"evidences\"] = [evidence_ids[id] for id in top_k_ids]\n","      claim_id = batch[\"claim_ids\"][index]\n","      output[claim_id] = data\n","  fout = open(\"./drive/MyDrive/NLP_ass3/predict/v2/test-claims-retrieved.json\", 'w')\n","  json.dump(output, fout)\n","  fout.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SYNnFfJup46o","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ab32e22605484a00bb44a9bd639fc3f7","7ec32d0230b3463aa460d05129ae8ab6","68aef7947b0c40c38c9f63a5515fbaf1","87a3038a1e6546789e3da10377bf875d","68fb0de922d4466f8d41f29b61529951","27cdfb297a91489993605349f2a9536b","9d7899fefef747e088ff71076b6f8375","94db5caaa68d45b7b5d4a0db5d4f83b2","42c55f1c14c043dc9f948f1a6222b3e8","a7d822e3faef45a09f6904a59fb9e794","ef8eb2fafd3a43188f67e5d454ba58e2","1556c844675641d396df9517f283648b","91dd12176c954a9aacc20a774360dc96","4bb9a8eb627f4ae9aaf90dee8bea8dd0","809638975e28470da16cef57ea4418a6","d5bf464393fb4d4f9fc92e6146aee142","c354d2512b2a4be7bdb09a9df6161982","4505878bcc0b406992ca2bfa994f5f44","805eb9bdd684422ba921d4d3652c32a5","3c50d41e20454100972122e616792ad0","fc6faf032712482a8211054683d8696d","642e5c5765344715b08705d69b48d522","706cdcf787504b19bfc64aa60e219fd9","5a544c2b23de4841bf1e1813ebdb12bf","2ca47ed69fda43d2803580fa73ff7934","583eed71f215418698f38c1074635322","89622287315d496f8591c8b9479d3d9c","c086e5f35fb749068f32640d4b6072fd","6e6e81ac82b445e5b76e6fdfe8ec8468","bce43050a7ca42fc994e770efd31951a","7855720bd80d4879aa166ba2416dfcec","98241b7c080a431487aa85f01cc580aa","052d7a87891a4d229fe94d141e697e46","434b28f07afa42fb9b3e78a31b353174","fe3243a1b04b4f7a89d1ca678ae38405","e8370c22a19149be9e46fa77dd92c256","89574b7e9e6645ad95f5115cae695c96","00e8916b8d29462a81539932d13c98d5","a14cd4e2b0d8476fbd3c6a79c6831ba6","19240f958438496cb7746aba95dfeb4b","c87c8a40d7b44c999f64bbcf56f4131a","27a901c32a1b48949b0b4d5e3770cc77","ad4e9ddba1ce4de494c9efad72224291","9fa9e4f08eae4146947dc8656990f38e","9da2c1119ac74ba6820c2d1e471c220c","14452e898a1543a9a1169054c04c2387","5e5141fe8dd64c13b7b74effaf6124f8","9317786e594c4cddb1770bf852edca16","df12c2cf660641778e04cc567f07e66f","f994f70853c44e4aacf6cae036f45bcc","ef9f3957ffe64ba5af8a7bf46a80c99a","7dcfa21442954a5c94c2be5be7a4596f","5fe9c90ab17548b185be1a9c44eb54b8","00deecd0035c452faa0a438878deb208","8395b2e78992441f99ed1354ae86629b","513f06c3a55f495b8c4283719f166055"]},"outputId":"3330bbaa-f14e-4af0-b13f-07b56d571ae3","executionInfo":{"status":"ok","timestamp":1683306224760,"user_tz":-600,"elapsed":7820004,"user":{"displayName":"Yixin Shen","userId":"08723041619229600532"}}},"outputs":[{"data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.1"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230505_125218-ephvsbav</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/377188503/Task1%20Evidence%20Retrieval/runs/ephvsbav' target=\"_blank\">DPR_v2_roberta-base_DifferentLR</a></strong> to <a href='https://wandb.ai/377188503/Task1%20Evidence%20Retrieval' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/377188503/Task1%20Evidence%20Retrieval' target=\"_blank\">https://wandb.ai/377188503/Task1%20Evidence%20Retrieval</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/377188503/Task1%20Evidence%20Retrieval/runs/ephvsbav' target=\"_blank\">https://wandb.ai/377188503/Task1%20Evidence%20Retrieval/runs/ephvsbav</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab32e22605484a00bb44a9bd639fc3f7","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1556c844675641d396df9517f283648b","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"706cdcf787504b19bfc64aa60e219fd9","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"434b28f07afa42fb9b3e78a31b353174","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9da2c1119ac74ba6820c2d1e471c220c","version_major":2,"version_minor":0},"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 9444/9444 [21:59<00:00,  7.16it/s]\n","100%|██████████| 20/20 [00:07<00:00,  2.75it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Evidence Retrieval F-score = 0.024\n","\n","##################################################Training##################################################\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 154/154 [00:40<00:00,  3.78it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["##################################################Evaluate##################################################\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 9444/9444 [21:59<00:00,  7.16it/s]\n","100%|██████████| 20/20 [00:07<00:00,  2.74it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Evidence Retrieval F-score = 0.066\n","\n","\n","This is the 1 epoch the max f_score is 0.0659400123685838\n","##################################################Training##################################################\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 154/154 [00:40<00:00,  3.80it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["##################################################Evaluate##################################################\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 9444/9444 [21:59<00:00,  7.16it/s]\n","100%|██████████| 20/20 [00:07<00:00,  2.74it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Evidence Retrieval F-score = 0.101\n","\n","\n","This is the 2 epoch the max f_score is 0.10051020408163265\n","##################################################Training##################################################\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 154/154 [00:41<00:00,  3.72it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["##################################################Evaluate##################################################\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 9444/9444 [22:01<00:00,  7.15it/s]\n","100%|██████████| 20/20 [00:07<00:00,  2.74it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Evidence Retrieval F-score = 0.110\n","\n","\n","This is the 3 epoch the max f_score is 0.11034322820037104\n","##################################################Training##################################################\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 154/154 [00:41<00:00,  3.68it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["##################################################Evaluate##################################################\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 9444/9444 [22:02<00:00,  7.14it/s]\n","100%|██████████| 20/20 [00:07<00:00,  2.74it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Evidence Retrieval F-score = 0.119\n","\n","\n","This is the 4 epoch the max f_score is 0.11924860853432281\n","##################################################Training##################################################\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 154/154 [00:41<00:00,  3.73it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["##################################################Evaluate##################################################\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9444/9444 [22:02<00:00,  7.14it/s]\n","100%|██████████| 20/20 [00:07<00:00,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evidence Retrieval F-score = 0.118\n","\n","##################################################Training##################################################\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 154/154 [00:41<00:00,  3.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["##################################################Evaluate##################################################\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9444/9444 [22:02<00:00,  7.14it/s]\n","100%|██████████| 20/20 [00:06<00:00,  3.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evidence Retrieval F-score = 0.148\n","\n","\n","This is the 6 epoch the max f_score is 0.14846938775510204\n","##################################################Training##################################################\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 154/154 [00:41<00:00,  3.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["##################################################Evaluate##################################################\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9444/9444 [22:02<00:00,  7.14it/s]\n","100%|██████████| 20/20 [00:06<00:00,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evidence Retrieval F-score = 0.131\n","\n","##################################################Training##################################################\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 154/154 [00:42<00:00,  3.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["##################################################Evaluate##################################################\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9444/9444 [22:03<00:00,  7.14it/s]\n","100%|██████████| 20/20 [00:06<00:00,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evidence Retrieval F-score = 0.129\n","\n","##################################################Training##################################################\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 154/154 [00:41<00:00,  3.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["##################################################Evaluate##################################################\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9444/9444 [22:02<00:00,  7.14it/s]\n","100%|██████████| 20/20 [00:07<00:00,  2.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evidence Retrieval F-score = 0.130\n","\n","##################################################Training##################################################\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 154/154 [00:41<00:00,  3.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["##################################################Evaluate##################################################\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9444/9444 [22:02<00:00,  7.14it/s]\n","100%|██████████| 20/20 [00:07<00:00,  2.75it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Evidence Retrieval F-score = 0.120\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.002 MB of 0.003 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.765759…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"513f06c3a55f495b8c4283719f166055"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>f_score</td><td>▁▃▅▆▆▆█▇▇▇▆</td></tr><tr><td>loss</td><td>█▅▅▅▄▃▃▃▂▃▂▂▂▂▂▂▁▂▂▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>f_score</td><td>0.1199</td></tr><tr><td>loss</td><td>1.24609</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">DPR_v2_roberta-base_DifferentLR</strong> at: <a href='https://wandb.ai/377188503/Task1%20Evidence%20Retrieval/runs/ephvsbav' target=\"_blank\">https://wandb.ai/377188503/Task1%20Evidence%20Retrieval/runs/ephvsbav</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230505_125218-ephvsbav/logs</code>"]},"metadata":{}}],"source":["# training settings\n","epoch = 10\n","batch_size = 8\n","max_length = 128\n","# max_length = 512\n","evidence_samples = 64\n","model_path = \"\"\n","# TODO, adjust the top_evidence number\n","top_evidence = 3\n","# initialize the pretrained model\n","# TODO, use different pretrained model\n","# model_name = \"bert-base-uncased\"\n","model_name = \"roberta-base\"\n","\n","train(model_name, epoch, batch_size, max_length, evidence_samples, top_evidence, model_path)\n","\n","# predict(model_name, batch_size, max_length, top_evidence, model_path)\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNq8nghZp/95VisOi2bhhw0"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ab32e22605484a00bb44a9bd639fc3f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7ec32d0230b3463aa460d05129ae8ab6","IPY_MODEL_68aef7947b0c40c38c9f63a5515fbaf1","IPY_MODEL_87a3038a1e6546789e3da10377bf875d"],"layout":"IPY_MODEL_68fb0de922d4466f8d41f29b61529951"}},"7ec32d0230b3463aa460d05129ae8ab6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27cdfb297a91489993605349f2a9536b","placeholder":"​","style":"IPY_MODEL_9d7899fefef747e088ff71076b6f8375","value":"Downloading (…)lve/main/config.json: 100%"}},"68aef7947b0c40c38c9f63a5515fbaf1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_94db5caaa68d45b7b5d4a0db5d4f83b2","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_42c55f1c14c043dc9f948f1a6222b3e8","value":481}},"87a3038a1e6546789e3da10377bf875d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7d822e3faef45a09f6904a59fb9e794","placeholder":"​","style":"IPY_MODEL_ef8eb2fafd3a43188f67e5d454ba58e2","value":" 481/481 [00:00&lt;00:00, 35.0kB/s]"}},"68fb0de922d4466f8d41f29b61529951":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27cdfb297a91489993605349f2a9536b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d7899fefef747e088ff71076b6f8375":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94db5caaa68d45b7b5d4a0db5d4f83b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42c55f1c14c043dc9f948f1a6222b3e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7d822e3faef45a09f6904a59fb9e794":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef8eb2fafd3a43188f67e5d454ba58e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1556c844675641d396df9517f283648b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_91dd12176c954a9aacc20a774360dc96","IPY_MODEL_4bb9a8eb627f4ae9aaf90dee8bea8dd0","IPY_MODEL_809638975e28470da16cef57ea4418a6"],"layout":"IPY_MODEL_d5bf464393fb4d4f9fc92e6146aee142"}},"91dd12176c954a9aacc20a774360dc96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c354d2512b2a4be7bdb09a9df6161982","placeholder":"​","style":"IPY_MODEL_4505878bcc0b406992ca2bfa994f5f44","value":"Downloading pytorch_model.bin: 100%"}},"4bb9a8eb627f4ae9aaf90dee8bea8dd0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_805eb9bdd684422ba921d4d3652c32a5","max":501200538,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c50d41e20454100972122e616792ad0","value":501200538}},"809638975e28470da16cef57ea4418a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc6faf032712482a8211054683d8696d","placeholder":"​","style":"IPY_MODEL_642e5c5765344715b08705d69b48d522","value":" 501M/501M [00:01&lt;00:00, 444MB/s]"}},"d5bf464393fb4d4f9fc92e6146aee142":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c354d2512b2a4be7bdb09a9df6161982":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4505878bcc0b406992ca2bfa994f5f44":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"805eb9bdd684422ba921d4d3652c32a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c50d41e20454100972122e616792ad0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc6faf032712482a8211054683d8696d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"642e5c5765344715b08705d69b48d522":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"706cdcf787504b19bfc64aa60e219fd9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5a544c2b23de4841bf1e1813ebdb12bf","IPY_MODEL_2ca47ed69fda43d2803580fa73ff7934","IPY_MODEL_583eed71f215418698f38c1074635322"],"layout":"IPY_MODEL_89622287315d496f8591c8b9479d3d9c"}},"5a544c2b23de4841bf1e1813ebdb12bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c086e5f35fb749068f32640d4b6072fd","placeholder":"​","style":"IPY_MODEL_6e6e81ac82b445e5b76e6fdfe8ec8468","value":"Downloading (…)olve/main/vocab.json: 100%"}},"2ca47ed69fda43d2803580fa73ff7934":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bce43050a7ca42fc994e770efd31951a","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7855720bd80d4879aa166ba2416dfcec","value":898823}},"583eed71f215418698f38c1074635322":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98241b7c080a431487aa85f01cc580aa","placeholder":"​","style":"IPY_MODEL_052d7a87891a4d229fe94d141e697e46","value":" 899k/899k [00:00&lt;00:00, 1.20MB/s]"}},"89622287315d496f8591c8b9479d3d9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c086e5f35fb749068f32640d4b6072fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e6e81ac82b445e5b76e6fdfe8ec8468":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bce43050a7ca42fc994e770efd31951a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7855720bd80d4879aa166ba2416dfcec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98241b7c080a431487aa85f01cc580aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"052d7a87891a4d229fe94d141e697e46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"434b28f07afa42fb9b3e78a31b353174":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fe3243a1b04b4f7a89d1ca678ae38405","IPY_MODEL_e8370c22a19149be9e46fa77dd92c256","IPY_MODEL_89574b7e9e6645ad95f5115cae695c96"],"layout":"IPY_MODEL_00e8916b8d29462a81539932d13c98d5"}},"fe3243a1b04b4f7a89d1ca678ae38405":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a14cd4e2b0d8476fbd3c6a79c6831ba6","placeholder":"​","style":"IPY_MODEL_19240f958438496cb7746aba95dfeb4b","value":"Downloading (…)olve/main/merges.txt: 100%"}},"e8370c22a19149be9e46fa77dd92c256":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c87c8a40d7b44c999f64bbcf56f4131a","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27a901c32a1b48949b0b4d5e3770cc77","value":456318}},"89574b7e9e6645ad95f5115cae695c96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad4e9ddba1ce4de494c9efad72224291","placeholder":"​","style":"IPY_MODEL_9fa9e4f08eae4146947dc8656990f38e","value":" 456k/456k [00:00&lt;00:00, 786kB/s]"}},"00e8916b8d29462a81539932d13c98d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a14cd4e2b0d8476fbd3c6a79c6831ba6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19240f958438496cb7746aba95dfeb4b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c87c8a40d7b44c999f64bbcf56f4131a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27a901c32a1b48949b0b4d5e3770cc77":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad4e9ddba1ce4de494c9efad72224291":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fa9e4f08eae4146947dc8656990f38e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9da2c1119ac74ba6820c2d1e471c220c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_14452e898a1543a9a1169054c04c2387","IPY_MODEL_5e5141fe8dd64c13b7b74effaf6124f8","IPY_MODEL_9317786e594c4cddb1770bf852edca16"],"layout":"IPY_MODEL_df12c2cf660641778e04cc567f07e66f"}},"14452e898a1543a9a1169054c04c2387":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f994f70853c44e4aacf6cae036f45bcc","placeholder":"​","style":"IPY_MODEL_ef9f3957ffe64ba5af8a7bf46a80c99a","value":"Downloading (…)/main/tokenizer.json: 100%"}},"5e5141fe8dd64c13b7b74effaf6124f8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7dcfa21442954a5c94c2be5be7a4596f","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5fe9c90ab17548b185be1a9c44eb54b8","value":1355863}},"9317786e594c4cddb1770bf852edca16":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00deecd0035c452faa0a438878deb208","placeholder":"​","style":"IPY_MODEL_8395b2e78992441f99ed1354ae86629b","value":" 1.36M/1.36M [00:00&lt;00:00, 7.07MB/s]"}},"df12c2cf660641778e04cc567f07e66f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f994f70853c44e4aacf6cae036f45bcc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef9f3957ffe64ba5af8a7bf46a80c99a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7dcfa21442954a5c94c2be5be7a4596f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fe9c90ab17548b185be1a9c44eb54b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"00deecd0035c452faa0a438878deb208":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8395b2e78992441f99ed1354ae86629b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}